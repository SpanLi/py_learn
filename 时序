# -*- coding: utf-8 -*-
"""
Created on Tue Dec 19 15:50:26 2017

@author: lixiaoqian

ADF检验总结一句话：如果序列是平稳的，则不存在单位根， 否则就会存在单位根。
ADF检验的原假设是存在单位根，因此如果得到的统计量显著小于3个置信度（1%，5%，10%）的临界统计值时，说明是拒绝原假设的。另外是看P-value是否非常接近0（4为小数基本即可。）

"""
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
from statsmodels.tsa.stattools import adfuller

def test_stationarity(timeseries):
    
    #这里以一年为一个窗口，每一个时间t的值由它前面12个月（包括自己）的均值代替，标准差同理。
    rolmean = pd.rolling_mean(timeseries,window=12)
    rolstd = pd.rolling_std(timeseries, window=12)
    
    #plot rolling statistics:
    fig = plt.figure()
    fig.add_subplot()
    orig = plt.plot(timeseries, color = 'blue',label='Original')
    mean = plt.plot(rolmean , color = 'red',label = 'rolling mean')
    std = plt.plot(rolstd, color = 'black', label= 'Rolling standard deviation')
    
    plt.legend(loc = 'best')
    plt.title('Rolling Mean & Standard Deviation')
    plt.show(block=False)
    
    
    #Dickey-Fuller test:
    
    print ('Results of Dickey-Fuller Test:')
    #adfuller单位根检验; AIC是衡量统计模型拟合优良性的一种标准
    #1%、%5、%10不同程度拒绝原假设的统计值和ADF Test Statistic的比较，Test Statistic同时小于1%、5%、10%即说明非常好地拒绝该假设
    #P-value是否非常接近0.本数据中
    dftest = adfuller(timeseries,autolag = 'AIC')
    #dftest的输出前一项依次为检测值，p值，滞后数，使用的观测数，各个置信度下的临界值
    dfoutput = pd.Series(dftest[0:4],index = ['Test Statistic','p-value','#Lags Used','Number of Observations Used'])
    for key,value in dftest[4].items():
        dfoutput['Critical value (%s)' %key] = value
    
    print (dfoutput)
    
dateparse = lambda dates: pd.datetime.strptime(dates, '%Y-%m')
data = pd.read_csv('AirPassengers.csv', parse_dates=['Month'], index_col='Month',date_parser=dateparse)   
ts = data['#Passengers']
test_stationarity(ts)

#让数据变得不稳定的原因主要有俩：
#   趋势（trend）-数据随着时间变化。比如说升高或者降低。
#   季节性(seasonality)-数据在特定的时间段内变动。比如说节假日，或者活动导致数据的异常。
#由于原数据值域范围比较大，为了缩小值域，同时保留其他信息，常用的方法是对数化，取log。
ts_log = np.log(ts)

moving_avg = pd.rolling_mean(ts_log,12)
    plt.plot(ts_log ,color = 'blue')
    plt.plot(moving_avg, color='red')

#然后作差：
ts_log_moving_avg_diff = ts_log-moving_avg
ts_log_moving_avg_diff.dropna(inplace = True)
test_stationarity(ts_log_moving_avg_diff)

#上面的方法是将所有的时间平等看待，而在许多情况下，可以认为越近的时刻越重要。所以引入指数加权移动平均-- Exponentially-weighted moving average.（pandas中通过ewma()函数提供了此功能。）
# halflife的值决定了衰减因子alpha：  alpha = 1 - exp(log(0.5) / halflife)
expweighted_avg = pd.ewma(ts_log,halflife=12)
ts_log_ewma_diff = ts_log - expweighted_avg
test_stationarity(ts_log_ewma_diff)


#检测和去除季节性
#有两种方法：
#1 差分化： 以特定滞后数目的时刻的值的作差
#2 分解： 对趋势和季节性分别建模在移除它们
ts_log_diff = ts_log - ts_log.shift()
ts_log_diff.dropna(inplace=True)
test_stationarity(ts_log_diff)



#分解(decomposing) 可以用来把时序数据中的趋势和周期性数据都分离出来:
#如图可以明显的看到，将original数据 拆分成了三份。Trend数据具有明显的趋势性，Seasonality数据具有明显的周期性，
#Residuals是剩余的部分，可以认为是去除了趋势和季节性数据之后，稳定的数据，是我们所需要的。
from statsmodels.tsa.seasonal import seasonal_decompose
def decompose(timeseries):
    
    # 返回包含三个部分 trend（趋势部分） ， seasonal（季节性部分） 和residual (残留部分)
    decomposition = seasonal_decompose(timeseries)
    
    trend = decomposition.trend
    seasonal = decomposition.seasonal
    residual = decomposition.resid
    
    plt.subplot(411)
    plt.plot(ts_log, label='Original')
    plt.legend(loc='best')
    plt.subplot(412)
    plt.plot(trend, label='Trend')
    plt.legend(loc='best')
    plt.subplot(413)
    plt.plot(seasonal,label='Seasonality')
    plt.legend(loc='best')
    plt.subplot(414)
    plt.plot(residual, label='Residuals')
    plt.legend(loc='best')
    plt.tight_layout()
    
    return trend , seasonal, residual
#消除了trend 和seasonal之后，只对residual部分作为想要的时序数据进行处理
trend , seasonal, residual = decompose(ts_log)
residual.dropna(inplace=True)
test_stationarity(residual)
#如图所示，数据的均值和方差趋于常数，几乎无波动(看上去比之前的陡峭，但是要注意他的值域只有[-0.05,0.05]之间)，所以直观上可以认为是稳定的数据。
#另外DFtest的结果显示，Statistic值原小于1%时的Critical value，所以在99%的置信度下，数据是稳定的。











